---
title: "2024 Prizes"
sidebar_label: "2024 Prizes"
hide_table_of_contents: true
slug: "2024_prizes"
---

<head>
  <html data-theme="dark" />

  <meta
    name="description"
    content="A $1,000,000+ machine learning and computer vision competition"
  />

  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://scrollprize.org" />
  <meta property="og:title" content="Vesuvius Challenge" />
  <meta
    property="og:description"
    content="A $1,000,000+ machine learning and computer vision competition"
  />
  <meta
    property="og:image"
    content="https://scrollprize.org/img/social/opengraph.jpg?2024-02-27"
  />

  <meta property="twitter:card" content="summary_large_image" />
  <meta property="twitter:url" content="https://scrollprize.org" />
  <meta property="twitter:title" content="Vesuvius Challenge" />
  <meta
    property="twitter:description"
    content="A $1,000,000+ machine learning and computer vision competition"
  />
  <meta
    property="twitter:image"
    content="https://scrollprize.org/img/social/opengraph.jpg?2024-02-27"
  />
</head>

We've got another exciting year of prizes, with the community goal of reading 90% of our scanned scrolls:

* $100,000 - **[2024 Grand Prize](#2024-grand-prize)** - Read 90% of each of Scrolls 1-4
* $50,000 - **[First Automated Segmentation Prize](#first-automated-segmentation-prize)** - Reproduce the 2023 Grand Prize result but faster
* 3 x $30,000 - **[First Letters Prizes](#3-first-letters-prizes-scrolls-2-3-and-4)** - Find the first letters in Scrolls 2, 3, and 4
* $350,000 - **[Monthly Progress Prizes](#monthly-progress-prizes)** - Open ended prizes from $1,000-20,000

Details below! This is a lot of information, and we want to help - bring your questions to our [Discord community](https://discord.gg/V4fJhvtaQn) or to [our team](mailto:team@scrollprize.org).

## 2024 Grand Prize

The primary goal for 2024 is to read 90% of each of Scrolls 1-4, and **we will issue the $100,000 2024 Grand Prize to the first team that is able to do this**. In 2023, we got from 0% to 5% of one scroll. Reading 90% of each of our scrolls will lay the foundation to read all 300 scrolls.

More details on the judging criteria will be available soon, but you can start now. We will look for large, contiguous segmentations, possibly a single segmentation for the bulk of each scroll. The segmentations should pass geometric sanity checks; for example, they cannot intersect themselves. We expect methods are going to need to operate in "true 3D" (as opposed to iterating through slices) and will need improved performance in compressed papyrus regions in order to meet this bar. We will also look for approaches that unwrap an entire scroll into a contiguous 2D view, showing the original layout of the papyrus sheet. Multiple tools in the pipeline will likely need updates to work with these larger segments.

## First Automated Segmentation Prize

We are awarding $50,000 to the first team to autosegment the 2023 Grand Prize region in Scroll 1, with quality matching or exceeding the manual segmentation from 2023 (comparable legibility and number of letters recovered). A second place $12,500 prize is also available for the second team to achieve this.

The [2023 Grand Prize](grandprize) showed that we can extract significant regions of text from inside a sealed Herculaneum scroll - but to scale up, these methods need to be significantly faster and cheaper. This prize asks you to reproduce a year of work in much less time. It sounds crazy, but we believe this is possible using improved automation!

<div className="mb-4">
  <img src="/img/2024-prizes/gp-segment-outlines.jpg" className="w-[100%]"/>
  <figcaption className="mt-[-6px]">The 2023 Grand Prize banner segments that this prize aims to reproduce.</figcaption>
</div>

We will judge the segmentation by the following criteria:
* **Inputs.** Maximum 4 hours of human input and 48 hours of compute (in any order). Existing 2023 Grand Prize segments (and overlapping ones) represent significant human input, so can only be used as inputs or training data if memorization is eliminated. Reach out to us for approval if you want to do this. Segments from elsewhere in the scroll can be used!
* **Outputs.** Our Segmentation, Technical, and Papyrological Teams will evaluate the segmentation:
  * **Geometric checks:** Single continuous segmentation. Manifold. No self-intersections. Can exceed 2023 Grand Prize banner, but must cover 95% of the 2023 Grand Prize banner.
  * **Segmentation accuracy.** Assessed by the Segmentation Team and the Technical Team.
  * **Flattening.** You don’t necessarily have to implement flattening (it is provided in at least Volume Cartographer), but if you do, it should be comparable to 2023 Grand Prize results.
  * **Ink detection.** Comparable or better ink detection as determined by our Papyrological Team. You can use the open source 2023 Grand Prize winning solution for this.

A submission requires:
* **Ink detection image.** Submissions must include an image of the virtually unrolled segment, showing visible and legible text.
  * Submit a single static image showing the text region. Images must be generated programmatically, as direct outputs of CT data inputs, and should not contain manual annotations of characters or text. Using annotations as training data is OK if they are not memorized by the model, for example if you use k-fold validation.
  * Include a scale bar on the submission image.
  * You may use open source methods (for example the 2023 Grand Prize winning submission) for ink detection.
* **Texture image.** Include a texture image showing the papyrus fiber structure of the segmented region.
  * You may use Volume Cartographer’s `vc_render` or other existing tools to do this.
  * This image must be aligned with the above ink detection image and have the same dimensions.
* **Segmentation files.** Provide the actual segmentation.
  * Expected format: A mesh file along with a UV map defining the flattening.
* **Proof of work.** Your result should be reproducible using approximately 4 hours of human input and 48 hours of compute time.
  * Provide evidence of this. For example, a video recording the manual parts of your process.
* **Methodology.** A detailed technical description of how your solution works. We need to be able to reproduce your work, so please make this as easy as possible:
  * For fully automated software, consider a Docker image that we can easily run to reproduce your work, and please include system requirements.
  * For software with a human in the loop, please provide written instructions and a video explaining how to use your tool. We’ll work with you to learn how to use it, but we’d like to have a strong starting point.
  * Please include an easily accessible link from which we can download it.

Submissions must be made by 11:59pm Pacific, December 31, 2024. Make your submission using [this form](https://forms.gle/PyrriG8XFut7kqJeA).

## 3 First Letters Prizes: Scrolls 2, 3, and 4

We’re issuing 3 more First Letters prizes!

* First Letters in Scroll 2: $30,000 1st place, $7,500 2nd place
* First Letters in Scroll 3: $30,000 1st place, $7,500 2nd place
* First Letters in Scroll 4: $30,000 1st place, $7,500 2nd place

<div className="mb-4">
  <img src="/img/firstletters/purple_card-new.png" className="w-[60%]"/>
  <figcaption className="mt-[-6px]">The first letters discovered in Scroll 1 in 2023.</figcaption>
</div>

For each scroll, $30,000 will be awarded to the first team that uncovers 25 letters within a single area of 10 cm<sup>2</sup>, and open sources their methods and results (***after*** winning the prize). $7,500 is also available for the second team to meet this bar.

The purpose of these prizes is to close the gap between our current state of the art and the seriously challenging 2024 Grand Prize. Last year we showed it is possible to recover text from a single rolled scroll. Generalizing these methods across multiple scrolls and scans will make them more robust, which will be needed to read the complete library.

A submission requires:
* **Image.** Submissions must be an image of the virtually unrolled segment, showing visible and legible text.
  * Submit a single static image showing the text region. Images must be generated programmatically, as direct outputs of CT data inputs, and should not contain manual annotations of characters or text.
  * Specify which scroll the image comes from. For multiple scrolls, please make multiple submissions.
  * Include a scale bar showing the size of 1 cm on the submission image.
  * Specify the 3D position of the text within the scroll. The easiest way to do this is to provide the segmentation file (or the segmentation ID, if using a public segmentation).
* **Methodology.** A detailed technical description of how your solution works. We need to be able to reproduce your work, so please make this as easy as possible:
  * For fully automated software, consider a Docker image that we can easily run to reproduce your work, and please include system requirements.
  * For software with a human in the loop, please provide written instructions and a video explaining how to use your tool. We’ll work with you to learn how to use it, but we’d like to have a strong starting point.
  * Please include an easily accessible link from which we can download it.
* **Hallucination mitigation.** If there is any risk of your model hallucinating results, please let us know how you mitigated that risk. Tell us why you are confident that the results you are getting are real.
  * We strongly discourage submissions that use window sizes larger than 0.5x0.5 mm to generate images from machine learning models. This corresponds to 64x64 pixels for 8 µm scans. If your submission uses larger window sizes, we may reject it and ask you to modify and resubmit.
* **Other information.** Feel free to include any other things we should know.

Your submission will be reviewed by the review teams to verify technical validity and papyrological plausibility and legibility.
Just as with the Grand Prize, please **do not** make your discovery public until winning the prize. We will work with you to announce your findings.

Submissions must be made by 11:59pm Pacific, December 31, 2024. Make your submission using [this form](https://forms.gle/KTyVkPyg35AVYyfd9).

## Monthly Progress Prizes

We’re awarding an estimated $350,000 this year in monthly progress prizes for submissions that get us closer to reading 90% of Scrolls 1-4. These prizes are more open-ended, and we have a wishlist to provide some ideas. If you are new to the project, this is a great place to start. Progress prizes will be awarded at a range of levels based on the contribution:

* Gold Aureus: $20,000 (estimated 4-8 per year) – for major contributions
* Denarius: $10,000 (estimated 10-15 per year)
* Sestertius: $2500 (estimated 25 per year)
* Papyrus: $1,000 (estimated 50 per year)

We favor submissions that:
* Are **released or open-sourced early**. Tools released earlier have a higher chance of being used for reading the scrolls than those released the last day of the month.
* Actually **get used**. We’ll look for signals from the community: questions, comments, bug reports, feature requests. Our Segmentation Team will publicly provide comments on tools they use.

Things we’d love to see – these encompass a wide range of award levels. Check back as we’ll update this list!

* 3D/volumetric ink detection, other creative ink detection approaches
* Improved tutorials and introductions
  * Pull requests to [our website](https://github.com/ScrollPrize/scrollprize-website) or standalone resources both accepted!
* Improvements to [Volume Cartographer](https://github.com/educelab/volume-cartographer). Examples:
  * Off-axis segmentation (allowing the slice direction to vary during segmentation)
  * Novel segmentation algorithms
  * Flattened segment preview
  * Ink detection preview
  * GUI improvements
  * Bug fixes
* Improvements to [ThaumatoAnakalyptor](https://github.com/schillij95/ThaumatoAnakalyptor). Examples:
  * Better solution for sheet stitching
  * Improved point cloud extraction
  * Improved mesh reconstruction
  * More details and other improvements are described in the [roadmap](https://github.com/schillij95/ThaumatoAnakalyptor/blob/main/documentation/ThaumatoAnakalyptor___Technical_Report_and_Roadmap.pdf)
* Analysis of multi-energy/multi-resolution scans to help identify the best scanning settings
* Automated deformable volume registration to align different scans (resolution, energy) of the same object
* New visualization tools
* Segmentation inspection/evaluation tools
  * Visually compare two flattened meshes of the same region: using a color map, for each pixel, plot the distance from segmentation(s) A to the nearest point in segmentation(s) B.
* Performance improvements to pipeline steps so they can handle larger segmentations:
  * Segmentation
  * Flattening
  * Rendering
  * Ink detection

Submissions will be evaluated monthly, and multiple submissions/awards per month are permitted. The first deadline is 11:59pm Pacific, March 31, 2024! Submit using [this form](https://forms.gle/J3LekrMSWgFxTmqu6).

## Terms and Conditions

Prizes are awarded at the sole discretion of Scroll Prize Inc. and are subject to review by our Technical Team, Segmentation Team, and Papyrological Team. We may issue more or fewer awards based on the spirit of the prize and the received submissions. You agree to make your method open source if you win a prize. It does not have to be open source at the time of submission, but you have to make it open source under a permissive license to accept the prize. Submissions for the First Automated Segmentation Prize, each First Letters Prize, and the 2024 Grand Prize will close once the winner is announced and their methods are open sourced. Scroll Prize Inc. reserves the right to modify prize terms at any time in order to more accurately reflect the spirit of the prize as designed. Prize winner must provide payment information to Scroll Prize Inc. within 30 days of prize announcement to receive prize.
